{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4883218",
   "metadata": {},
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac720d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b8e9ee",
   "metadata": {},
   "source": [
    "# 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6de83b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dir = 'output_dataset/train'\n",
    "val_dir = 'output_dataset/val'\n",
    "test_dir = 'output_dataset/test'\n",
    "\n",
    "train_dataset = ImageFolder(root=train_dir, transform=transform)\n",
    "val_dataset = ImageFolder(root=val_dir, transform=transform)\n",
    "test_dataset = ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Dataset sizes\n",
    "dataset_sizes = {\n",
    "    'train': len(train_dataset),\n",
    "    'val': len(val_dataset)\n",
    "}\n",
    "\n",
    "# Data loaders dictionary\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61421e22",
   "metadata": {},
   "source": [
    "# 3. Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05f5446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained ResNet18 model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify the final fully connected layer for your specific task\n",
    "num_classes = len(train_dataset.classes)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f36d1fc",
   "metadata": {},
   "source": [
    "# 4. Fine-tune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80be92eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "train Loss: 1.2309 Acc: 51.1905\n",
      "val Loss: 2.0879 Acc: 45.5556\n",
      "\n",
      "Epoch 2/10\n",
      "train Loss: 0.8436 Acc: 68.3333\n",
      "val Loss: 7.7481 Acc: 30.0000\n",
      "\n",
      "Epoch 3/10\n",
      "train Loss: 0.7612 Acc: 70.4762\n",
      "val Loss: 3.0842 Acc: 32.2222\n",
      "\n",
      "Epoch 4/10\n",
      "train Loss: 0.7633 Acc: 68.8095\n",
      "val Loss: 2.1591 Acc: 38.8889\n",
      "\n",
      "Epoch 5/10\n",
      "train Loss: 0.6998 Acc: 73.8095\n",
      "val Loss: 1.9833 Acc: 55.5556\n",
      "\n",
      "Epoch 6/10\n",
      "train Loss: 0.5543 Acc: 78.0952\n",
      "val Loss: 1.2153 Acc: 53.3333\n",
      "\n",
      "Epoch 7/10\n",
      "train Loss: 0.4563 Acc: 83.0952\n",
      "val Loss: 2.5864 Acc: 65.5556\n",
      "\n",
      "Epoch 8/10\n",
      "train Loss: 0.3579 Acc: 85.7143\n",
      "val Loss: 1.2975 Acc: 64.4444\n",
      "\n",
      "Epoch 9/10\n",
      "train Loss: 0.2854 Acc: 90.0000\n",
      "val Loss: 1.1662 Acc: 65.5556\n",
      "\n",
      "Epoch 10/10\n",
      "train Loss: 0.2302 Acc: 92.3810\n",
      "val Loss: 1.1336 Acc: 62.2222\n",
      "\n",
      "Training complete in 16m 17s\n",
      "Best val Acc: 65.5556\n"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Learning rate scheduler\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # Initialize history dictionary to store metrics\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch + 1}/{num_epochs}')\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc * 100:.4f}')\n",
    "\n",
    "            # Store in history\n",
    "            history[f'{phase}_loss'].append(epoch_loss)\n",
    "            history[f'{phase}_acc'].append(epoch_acc.item())  # Convert tensor to float\n",
    "\n",
    "            # Save best model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'\\nTraining complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc * 100:.4f}')\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history\n",
    "\n",
    "# Train the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model, history = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683707a0",
   "metadata": {},
   "source": [
    "# 5. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bd1897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'resnet18_baseline.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cef442",
   "metadata": {},
   "source": [
    "# 6. Prune the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b88ba0",
   "metadata": {},
   "source": [
    "### 6.1 Load pretrained baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8feecf6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load the pretrained ResNet18 with 4 output classes\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 4)  # Adjust for 4 classes\n",
    "model.load_state_dict(torch.load('resnet18_baseline.pth'))  # Make sure you've saved baseline\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f265a91",
   "metadata": {},
   "source": [
    "### 6.2 Prunning configuration with 30% Weights pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aba819d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "def prune_and_remove(model, amount=0.3):\n",
    "    \"\"\"\n",
    "    Prunes 30% of weights in all Conv2d and Linear layers, then makes it permanent.\n",
    "    \"\"\"\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            # Apply unstructured L1 pruning\n",
    "            prune.l1_unstructured(module, name='weight', amount=amount)\n",
    "            # Remove the pruning mask and make it permanent\n",
    "            prune.remove(module, 'weight')\n",
    "    return model\n",
    "\n",
    "pruned_model = prune_and_remove(model, amount=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c385e45",
   "metadata": {},
   "source": [
    "### 6.3 Train pruned model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8b20cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "train Loss: 0.3137 Acc: 88.5714\n",
      "val Loss: 1.1355 Acc: 61.1111\n",
      "\n",
      "Epoch 2/10\n",
      "train Loss: 0.1591 Acc: 94.2857\n",
      "val Loss: 1.1537 Acc: 62.2222\n",
      "\n",
      "Epoch 3/10\n",
      "train Loss: 0.0872 Acc: 97.3810\n",
      "val Loss: 1.2453 Acc: 58.8889\n",
      "\n",
      "Epoch 4/10\n",
      "train Loss: 0.0804 Acc: 98.5714\n",
      "val Loss: 1.3401 Acc: 62.2222\n",
      "\n",
      "Epoch 5/10\n",
      "train Loss: 0.0545 Acc: 98.5714\n",
      "val Loss: 1.2387 Acc: 65.5556\n",
      "\n",
      "Epoch 6/10\n",
      "train Loss: 0.0341 Acc: 99.5238\n",
      "val Loss: 1.2671 Acc: 61.1111\n",
      "\n",
      "Epoch 7/10\n",
      "train Loss: 0.0341 Acc: 99.5238\n",
      "val Loss: 1.3026 Acc: 64.4444\n",
      "\n",
      "Epoch 8/10\n",
      "train Loss: 0.0323 Acc: 98.8095\n",
      "val Loss: 1.2756 Acc: 64.4444\n",
      "\n",
      "Epoch 9/10\n",
      "train Loss: 0.0265 Acc: 99.7619\n",
      "val Loss: 1.2860 Acc: 64.4444\n",
      "\n",
      "Epoch 10/10\n",
      "train Loss: 0.0291 Acc: 99.5238\n",
      "val Loss: 1.3159 Acc: 64.4444\n",
      "\n",
      "Training complete in 16m 60s\n",
      "Best val Acc: 65.5556\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(pruned_model.parameters(), lr=0.0001)\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Train again\n",
    "pruned_model, pruned_history = train_model(pruned_model, criterion, optimizer, exp_lr_scheduler, num_epochs=10)\n",
    "\n",
    "# Save pruned model\n",
    "torch.save(pruned_model.state_dict(), 'resnet18_pruned.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa41bfa5",
   "metadata": {},
   "source": [
    "# 7. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ade3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Accuracy: 86.04%\n",
      "Pruned Model Accuracy: 87.14%\n"
     ]
    }
   ],
   "source": [
    "# Define evaluation function\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# Evaluate baseline model\n",
    "model.load_state_dict(torch.load('resnet18_baseline.pth'))\n",
    "baseline_accuracy = evaluate_model(model, test_loader)\n",
    "print(f'Baseline Model Accuracy: {baseline_accuracy:.2f}%')\n",
    "\n",
    "# Evaluate pruned model\n",
    "model.load_state_dict(torch.load('resnet18_pruned.pth'))\n",
    "pruned_accuracy = evaluate_model(model, test_loader)\n",
    "print(f'Pruned Model Accuracy: {pruned_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d428c98d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
