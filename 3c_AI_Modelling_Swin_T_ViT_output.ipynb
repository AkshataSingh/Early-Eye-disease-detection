{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c051e9b5",
   "metadata": {},
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddffd527",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T13:44:38.497440Z",
     "iopub.status.busy": "2025-05-14T13:44:38.496891Z",
     "iopub.status.idle": "2025-05-14T13:44:43.474627Z",
     "shell.execute_reply": "2025-05-14T13:44:43.473836Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import timm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fca171c",
   "metadata": {},
   "source": [
    "# 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32d85cff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T13:44:43.478005Z",
     "iopub.status.busy": "2025-05-14T13:44:43.477646Z",
     "iopub.status.idle": "2025-05-14T13:44:43.488918Z",
     "shell.execute_reply": "2025-05-14T13:44:43.488185Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define transformations\n",
    "# Transforms\n",
    "IMAGE_SIZE = 256\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dir = 'output_dataset/train'\n",
    "val_dir = 'output_dataset/val'\n",
    "test_dir = 'output_dataset/test'\n",
    "\n",
    "# Hyperparameters\n",
    "MODEL_NAME = 'swinv2_tiny_window8_256'\n",
    "\n",
    "NUM_CLASSES = 4\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 5e-4\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "\n",
    "train_dataset = ImageFolder(root=train_dir, transform=transform)\n",
    "val_dataset = ImageFolder(root=val_dir, transform=transform)\n",
    "test_dataset = ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Dataset sizes\n",
    "dataset_sizes = {\n",
    "    'train': len(train_dataset),\n",
    "    'val': len(val_dataset)\n",
    "}\n",
    "\n",
    "# Data loaders dictionary\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4636681",
   "metadata": {},
   "source": [
    "# 3. Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64258484",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T13:44:43.491748Z",
     "iopub.status.busy": "2025-05-14T13:44:43.491314Z",
     "iopub.status.idle": "2025-05-14T13:44:54.486271Z",
     "shell.execute_reply": "2025-05-14T13:44:54.485539Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load pretrained Swin-Tiny model with classification head for 4 classes\n",
    "model = timm.create_model('swinv2_tiny_window8_256', pretrained=True, num_classes=4)\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb03469b",
   "metadata": {},
   "source": [
    "# 4. Fine-tune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75a57f77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T13:44:54.489608Z",
     "iopub.status.busy": "2025-05-14T13:44:54.489372Z",
     "iopub.status.idle": "2025-05-14T14:05:25.163988Z",
     "shell.execute_reply": "2025-05-14T14:05:25.162975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-4fd80fc6c0e0>:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()  # For AMP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-4fd80fc6c0e0>:46: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.set_grad_enabled(phase == 'train'), autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.2703 Acc: 48.8095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2184 Acc: 50.0000\n",
      "\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.1752 Acc: 55.9524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1311 Acc: 56.6667\n",
      "\n",
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0880 Acc: 59.2857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0855 Acc: 55.5556\n",
      "\n",
      "Epoch 4/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0118 Acc: 64.7619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0822 Acc: 56.6667\n",
      "\n",
      "Epoch 5/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.9026 Acc: 68.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0152 Acc: 65.5556\n",
      "\n",
      "Epoch 6/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7963 Acc: 77.6190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1785 Acc: 56.6667\n",
      "\n",
      "Epoch 7/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6501 Acc: 85.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0357 Acc: 71.1111\n",
      "\n",
      "Epoch 8/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5498 Acc: 90.9524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.9532 Acc: 74.4444\n",
      "\n",
      "Epoch 9/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4604 Acc: 95.9524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0574 Acc: 68.8889\n",
      "\n",
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4133 Acc: 97.6190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1260 Acc: 68.8889\n",
      "\n",
      "Epoch 11/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3879 Acc: 98.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1204 Acc: 70.0000\n",
      "\n",
      "Epoch 12/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3779 Acc: 99.5238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1998 Acc: 66.6667\n",
      "\n",
      "Epoch 13/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3621 Acc: 99.7619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1223 Acc: 72.2222\n",
      "\n",
      "Epoch 14/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3588 Acc: 99.7619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1362 Acc: 70.0000\n",
      "\n",
      "Epoch 15/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3725 Acc: 98.8095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1207 Acc: 67.7778\n",
      "\n",
      "Epoch 16/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3682 Acc: 99.7619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1907 Acc: 72.2222\n",
      "\n",
      "Epoch 17/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3630 Acc: 99.5238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1258 Acc: 67.7778\n",
      "\n",
      "Epoch 18/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3599 Acc: 99.7619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1524 Acc: 68.8889\n",
      "\n",
      "Epoch 19/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3553 Acc: 100.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1193 Acc: 68.8889\n",
      "\n",
      "Epoch 20/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3616 Acc: 99.5238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1379 Acc: 68.8889\n",
      "\n",
      "Epoch 21/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3665 Acc: 99.2857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1545 Acc: 67.7778\n",
      "\n",
      "Epoch 22/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3547 Acc: 100.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1477 Acc: 67.7778\n",
      "\n",
      "Epoch 23/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3549 Acc: 100.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1440 Acc: 68.8889\n",
      "\n",
      "Epoch 24/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3542 Acc: 100.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1443 Acc: 68.8889\n",
      "\n",
      "Epoch 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3536 Acc: 100.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1440 Acc: 68.8889\n",
      "\n",
      "Training complete in 20m 31s\n",
      "Best val Acc: 74.4444\n"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "LABEL_SMOOTHING = 0.1\n",
    "WEIGHT_DECAY = 0.01\n",
    "NUM_EPOCHS = 25\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTHING)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "\n",
    "scaler = GradScaler()  # For AMP\n",
    "\n",
    "# Training function\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=NUM_EPOCHS):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # Initialize history dictionary to store metrics\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch + 1}/{num_epochs}')\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'), autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        scaler.scale(loss).backward()\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update() \n",
    "                    \n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc * 100:.4f}')\n",
    "\n",
    "            # Store in history\n",
    "            history[f'{phase}_loss'].append(epoch_loss)\n",
    "            history[f'{phase}_acc'].append(epoch_acc.item())  # Convert tensor to float\n",
    "\n",
    "            # Save best model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'\\nTraining complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc * 100:.4f}')\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history\n",
    "\n",
    "# Train the model\n",
    "model, history = train_model(model, criterion, optimizer, scheduler, num_epochs=NUM_EPOCHS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726cf64a",
   "metadata": {},
   "source": [
    "# 5. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b1fa660",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T14:05:25.170757Z",
     "iopub.status.busy": "2025-05-14T14:05:25.169324Z",
     "iopub.status.idle": "2025-05-14T14:05:25.419726Z",
     "shell.execute_reply": "2025-05-14T14:05:25.418968Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'swin_t_baseline.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebf075f",
   "metadata": {},
   "source": [
    "# 6. Prune the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d3473d",
   "metadata": {},
   "source": [
    "### 6.1 Load pretrained baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5a59244",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T14:05:25.429370Z",
     "iopub.status.busy": "2025-05-14T14:05:25.424894Z",
     "iopub.status.idle": "2025-05-14T14:05:26.473308Z",
     "shell.execute_reply": "2025-05-14T14:05:26.472546Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize model without loading pretrained weights from ImageNet (we'll load our own)\n",
    "model = timm.create_model('swinv2_tiny_window8_256', pretrained=False, num_classes=4)\n",
    "\n",
    "# Load your own saved trained weights\n",
    "model.load_state_dict(torch.load('swin_t_baseline.pth'))\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2a2917",
   "metadata": {},
   "source": [
    "### 6.2 Prunning configuration with 30% Weights pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5a19d8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T14:05:26.478408Z",
     "iopub.status.busy": "2025-05-14T14:05:26.477153Z",
     "iopub.status.idle": "2025-05-14T14:05:26.740512Z",
     "shell.execute_reply": "2025-05-14T14:05:26.739663Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "def prune_and_remove(model, amount=0.3):\n",
    "    \"\"\"\n",
    "    Prunes 30% of weights in all Conv2d and Linear layers, then makes it permanent.\n",
    "    \"\"\"\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            # Apply unstructured L1 pruning\n",
    "            prune.l1_unstructured(module, name='weight', amount=amount)\n",
    "            # Remove the pruning mask and make it permanent\n",
    "            prune.remove(module, 'weight')\n",
    "    return model\n",
    "\n",
    "pruned_model = prune_and_remove(model, amount=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4ffb5a",
   "metadata": {},
   "source": [
    "### 6.3 Train pruned model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9a28b6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T14:05:26.746388Z",
     "iopub.status.busy": "2025-05-14T14:05:26.745008Z",
     "iopub.status.idle": "2025-05-14T14:13:37.892830Z",
     "shell.execute_reply": "2025-05-14T14:13:37.891356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-589c0ef5ef8e>:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()  # For AMP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-4fd80fc6c0e0>:46: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.set_grad_enabled(phase == 'train'), autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7161 Acc: 83.8095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.9739 Acc: 70.0000\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4958 Acc: 94.5238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0669 Acc: 70.0000\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4539 Acc: 95.4762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2055 Acc: 63.3333\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4215 Acc: 97.1429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0916 Acc: 67.7778\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3884 Acc: 98.0952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1823 Acc: 66.6667\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3878 Acc: 98.8095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1295 Acc: 72.2222\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3768 Acc: 98.8095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1562 Acc: 67.7778\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3666 Acc: 99.5238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1821 Acc: 67.7778\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3595 Acc: 99.7619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1778 Acc: 67.7778\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3604 Acc: 99.5238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1780 Acc: 67.7778\n",
      "\n",
      "Training complete in 8m 11s\n",
      "Best val Acc: 72.2222\n"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer for pruned model\n",
    "LABEL_SMOOTHING = 0.1\n",
    "WEIGHT_DECAY = 0.01\n",
    "NUM_EPOCHS = 10  # or adjust as needed\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTHING)\n",
    "optimizer = torch.optim.AdamW(pruned_model.parameters(), lr=1e-4, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Learning rate scheduler for pruned model\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "\n",
    "scaler = GradScaler()  # For AMP\n",
    "\n",
    "# Training function remains the same\n",
    "pruned_model, pruned_history = train_model(pruned_model, criterion, optimizer, scheduler, num_epochs=10)\n",
    "\n",
    "# Save pruned model\n",
    "torch.save(pruned_model.state_dict(), 'swin_t_pruned.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87844bb6",
   "metadata": {},
   "source": [
    "# 7. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac41dc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T14:13:37.899101Z",
     "iopub.status.busy": "2025-05-14T14:13:37.897850Z",
     "iopub.status.idle": "2025-05-14T14:13:56.424456Z",
     "shell.execute_reply": "2025-05-14T14:13:56.423429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Accuracy: 91.45%\n",
      "Pruned Model Accuracy: 92.98%\n"
     ]
    }
   ],
   "source": [
    "# Define evaluation function\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Evaluate baseline model\n",
    "model.load_state_dict(torch.load('swin_t_baseline.pth'))\n",
    "baseline_accuracy = evaluate_model(model, test_loader)\n",
    "print(f'Baseline Model Accuracy: {baseline_accuracy:.2f}%')\n",
    "\n",
    "# Evaluate pruned model\n",
    "model.load_state_dict(torch.load('swin_t_pruned.pth'))\n",
    "pruned_accuracy = evaluate_model(model, test_loader)\n",
    "print(f'Pruned Model Accuracy: {pruned_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f596d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fddcfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
