{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "123d8bb2",
   "metadata": {},
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f7db3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e7ca87",
   "metadata": {},
   "source": [
    "# 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f56b0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations specific to EfficientNetV2\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),  # Specific size for EfficientNetV2\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dir = 'output_dataset/train'\n",
    "val_dir = 'output_dataset/val'\n",
    "test_dir = 'output_dataset/test'\n",
    "\n",
    "train_dataset = ImageFolder(root=train_dir, transform=transform)\n",
    "val_dataset = ImageFolder(root=val_dir, transform=transform)\n",
    "test_dataset = ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Dataset sizes\n",
    "dataset_sizes = {\n",
    "    'train': len(train_dataset),\n",
    "    'val': len(val_dataset)\n",
    "}\n",
    "\n",
    "# Data loaders dictionary\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bd96c5",
   "metadata": {},
   "source": [
    "# 3. Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3655ed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained EfficientNetV2 model\n",
    "model = models.efficientnet_v2_s(pretrained=True)\n",
    "\n",
    "# Modify the final fully connected layer for your specific task\n",
    "num_classes = len(train_dataset.classes)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd447db2",
   "metadata": {},
   "source": [
    "# 4. Fine-tune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1495a9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/15\n",
      "train Loss: 1.1419 Acc: 51.1905\n",
      "val Loss: 6.0453 Acc: 17.7778\n",
      "\n",
      "Epoch 2/15\n",
      "train Loss: 1.0303 Acc: 58.8095\n",
      "val Loss: 1.2880 Acc: 41.1111\n",
      "\n",
      "Epoch 3/15\n",
      "train Loss: 0.7727 Acc: 68.0952\n",
      "val Loss: 1.2831 Acc: 52.2222\n",
      "\n",
      "Epoch 4/15\n",
      "train Loss: 0.6501 Acc: 75.9524\n",
      "val Loss: 1.0251 Acc: 70.0000\n",
      "\n",
      "Epoch 5/15\n",
      "train Loss: 0.5831 Acc: 81.6667\n",
      "val Loss: 1.2440 Acc: 51.1111\n",
      "\n",
      "Epoch 6/15\n",
      "train Loss: 0.5071 Acc: 81.6667\n",
      "val Loss: 1.4216 Acc: 63.3333\n",
      "\n",
      "Epoch 7/15\n",
      "train Loss: 0.5471 Acc: 81.6667\n",
      "val Loss: 1.0551 Acc: 64.4444\n",
      "\n",
      "Epoch 8/15\n",
      "train Loss: 0.2620 Acc: 92.3810\n",
      "val Loss: 0.9872 Acc: 64.4444\n",
      "\n",
      "Epoch 9/15\n",
      "train Loss: 0.2215 Acc: 93.8095\n",
      "val Loss: 0.8717 Acc: 67.7778\n",
      "\n",
      "Epoch 10/15\n",
      "train Loss: 0.1329 Acc: 95.9524\n",
      "val Loss: 0.9541 Acc: 68.8889\n",
      "\n",
      "Epoch 11/15\n",
      "train Loss: 0.1013 Acc: 96.9048\n",
      "val Loss: 0.9887 Acc: 67.7778\n",
      "\n",
      "Epoch 12/15\n",
      "train Loss: 0.1245 Acc: 96.1905\n",
      "val Loss: 0.9548 Acc: 70.0000\n",
      "\n",
      "Epoch 13/15\n",
      "train Loss: 0.0677 Acc: 98.3333\n",
      "val Loss: 1.0229 Acc: 67.7778\n",
      "\n",
      "Epoch 14/15\n",
      "train Loss: 0.0528 Acc: 98.8095\n",
      "val Loss: 1.0854 Acc: 70.0000\n",
      "\n",
      "Epoch 15/15\n",
      "train Loss: 0.0382 Acc: 99.5238\n",
      "val Loss: 1.0487 Acc: 70.0000\n",
      "\n",
      "Training complete in 72m 57s\n",
      "Best val Acc: 70.0000\n"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Learning rate scheduler\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # Initialize history dictionary to store metrics\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch + 1}/{num_epochs}')\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc * 100:.4f}')\n",
    "\n",
    "            # Store in history\n",
    "            history[f'{phase}_loss'].append(epoch_loss)\n",
    "            history[f'{phase}_acc'].append(epoch_acc.item())  # Convert tensor to float\n",
    "\n",
    "            # Save best model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'\\nTraining complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc * 100:.4f}')\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history\n",
    "\n",
    "# Train the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model, history = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa11be7",
   "metadata": {},
   "source": [
    "# 5. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1255f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'efficientnetv2_baseline.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b9bcb1",
   "metadata": {},
   "source": [
    "# 6. Prune the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f2e26e",
   "metadata": {},
   "source": [
    "### 6.1 Define baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6901b661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load pre-trained EfficientNetV2 model\n",
    "model = models.efficientnet_v2_s(pretrained=True)\n",
    "\n",
    "num_classes = 4 \n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "\n",
    "# Load your own saved trained weights\n",
    "model.load_state_dict(torch.load('efficientnetv2_baseline.pth'))\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb173b7",
   "metadata": {},
   "source": [
    "### 6.2 Prunning configuration with 30% Weights pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc35b57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "def prune_and_remove(model, amount=0.3):\n",
    "    \"\"\"\n",
    "    Prunes 30% of weights in all Conv2d and Linear layers, then makes it permanent.\n",
    "    \"\"\"\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            # Apply unstructured L1 pruning\n",
    "            prune.l1_unstructured(module, name='weight', amount=amount)\n",
    "            # Remove the pruning mask and make it permanent\n",
    "            prune.remove(module, 'weight')\n",
    "    return model\n",
    "\n",
    "pruned_model = prune_and_remove(model, amount=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cc4170",
   "metadata": {},
   "source": [
    "### 6.3 Train pruned model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "984ba22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/15\n",
      "train Loss: 0.3949 Acc: 86.1905\n",
      "val Loss: 0.8649 Acc: 70.0000\n",
      "\n",
      "Epoch 2/15\n",
      "train Loss: 0.2314 Acc: 91.6667\n",
      "val Loss: 1.1133 Acc: 68.8889\n",
      "\n",
      "Epoch 3/15\n",
      "train Loss: 0.1626 Acc: 94.7619\n",
      "val Loss: 1.0957 Acc: 70.0000\n",
      "\n",
      "Epoch 4/15\n",
      "train Loss: 0.1004 Acc: 97.6190\n",
      "val Loss: 1.1827 Acc: 68.8889\n",
      "\n",
      "Epoch 5/15\n",
      "train Loss: 0.0685 Acc: 98.0952\n",
      "val Loss: 1.1387 Acc: 71.1111\n",
      "\n",
      "Epoch 6/15\n",
      "train Loss: 0.0439 Acc: 99.2857\n",
      "val Loss: 1.2786 Acc: 71.1111\n",
      "\n",
      "Epoch 7/15\n",
      "train Loss: 0.0424 Acc: 99.0476\n",
      "val Loss: 1.2527 Acc: 71.1111\n",
      "\n",
      "Epoch 8/15\n",
      "train Loss: 0.0340 Acc: 99.2857\n",
      "val Loss: 1.1881 Acc: 70.0000\n",
      "\n",
      "Epoch 9/15\n",
      "train Loss: 0.0411 Acc: 98.8095\n",
      "val Loss: 1.2284 Acc: 70.0000\n",
      "\n",
      "Epoch 10/15\n",
      "train Loss: 0.0541 Acc: 98.3333\n",
      "val Loss: 1.1977 Acc: 70.0000\n",
      "\n",
      "Epoch 11/15\n",
      "train Loss: 0.0699 Acc: 97.8571\n",
      "val Loss: 1.3282 Acc: 71.1111\n",
      "\n",
      "Epoch 12/15\n",
      "train Loss: 0.0429 Acc: 99.2857\n",
      "val Loss: 1.3577 Acc: 71.1111\n",
      "\n",
      "Epoch 13/15\n",
      "train Loss: 0.0275 Acc: 100.0000\n",
      "val Loss: 1.2364 Acc: 70.0000\n",
      "\n",
      "Epoch 14/15\n",
      "train Loss: 0.0308 Acc: 99.7619\n",
      "val Loss: 1.1838 Acc: 68.8889\n",
      "\n",
      "Epoch 15/15\n",
      "train Loss: 0.0482 Acc: 99.2857\n",
      "val Loss: 1.2224 Acc: 68.8889\n",
      "\n",
      "Training complete in 57m 12s\n",
      "Best val Acc: 71.1111\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(pruned_model.parameters(), lr=0.0001)\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Train again\n",
    "pruned_model, pruned_history = train_model(pruned_model, criterion, optimizer, exp_lr_scheduler, num_epochs=15)\n",
    "\n",
    "# Save pruned model\n",
    "torch.save(pruned_model.state_dict(), 'efficientnetv2_pruned.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc6d418",
   "metadata": {},
   "source": [
    "# 7. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb3ac27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Accuracy: 89.13%\n",
      "Pruned Model Accuracy: 89.83%\n"
     ]
    }
   ],
   "source": [
    "# Define evaluation function\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Evaluate baseline model\n",
    "model.load_state_dict(torch.load('efficientnetv2_baseline.pth'))\n",
    "baseline_accuracy = evaluate_model(model, test_loader)\n",
    "print(f'Baseline Model Accuracy: {baseline_accuracy:.2f}%')\n",
    "\n",
    "# Evaluate pruned model\n",
    "model.load_state_dict(torch.load('efficientnetv2_pruned.pth'))\n",
    "pruned_accuracy = evaluate_model(model, test_loader)\n",
    "print(f'Pruned Model Accuracy: {pruned_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c990db3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
